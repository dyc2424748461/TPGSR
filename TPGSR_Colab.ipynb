{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dyc2424748461/TPGSR/blob/main/TPGSR_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# TPGSR: Text Prior Guided Scene Text Image Super-Resolution\n",
    "\n",
    "This notebook demonstrates how to run TPGSR (Text Prior Guided Scene Text Image Super-Resolution) in Google Colab.\n",
    "\n",
    "Paper: [Text Prior Guided Scene Text Image Super-resolution](https://arxiv.org/abs/2106.15368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/dyc2424748461/TPGSR.git\n",
    "%cd TPGSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch==1.2.0 torchvision==0.4.0\n",
    "!pip install numpy==1.18.0\n",
    "!pip install Pillow==6.2.2\n",
    "!pip install lmdb easydict pyfasttext editdistance tensorboardX\n",
    "!pip install pyyaml scipy matplotlib tqdm opencv-python\n",
    "!pip install IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_data"
   },
   "source": [
    "## 2. Download Dataset and Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_textzoom"
   },
   "outputs": [],
   "source": [
    "# Download TextZoom dataset\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Download TextZoom dataset from Google Drive\n",
    "print(\"Downloading TextZoom dataset...\")\n",
    "gdown.download('https://drive.google.com/uc?id=1WKVhB2qFjqQUqy8KVqtgEQZCsn2hZ8kV', 'data/TextZoom.zip', quiet=False)\n",
    "\n",
    "# Extract dataset\n",
    "!cd data && unzip -q TextZoom.zip\n",
    "print(\"TextZoom dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "# Download pretrained recognizer models\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "# Create pretrained directory\n",
    "os.makedirs('pretrained', exist_ok=True)\n",
    "\n",
    "# Download ASTER model\n",
    "print(\"Downloading ASTER model...\")\n",
    "gdown.download('https://drive.google.com/uc?id=1sOqiX9cqOgXV0qbMHTwl5eSV_5_d1gwc', 'pretrained/aster.pth.tar', quiet=False)\n",
    "\n",
    "# Download MORAN model\n",
    "print(\"Downloading MORAN model...\")\n",
    "gdown.download('https://drive.google.com/uc?id=1YLDHhtc5EyRNyhvNQS6ywC9htkdT4c7q', 'pretrained/moran.pth', quiet=False)\n",
    "\n",
    "# Download CRNN model\n",
    "print(\"Downloading CRNN model...\")\n",
    "gdown.download('https://drive.google.com/uc?id=1ooaHefQp0wDATLvOZlsXyLCjjWiHSHKX', 'pretrained/crnn.pth', quiet=False)\n",
    "\n",
    "print(\"All pretrained models downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 3. Configuration Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "update_config"
   },
   "outputs": [],
   "source": [
    "# Update configuration file for Colab environment\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "# Load configuration\n",
    "with open('config/super_resolution.yaml', 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Update paths for Colab\n",
    "config['TRAIN']['train_data_dir'] = [\n",
    "    '/content/TPGSR/data/TextZoom/train1',\n",
    "    '/content/TPGSR/data/TextZoom/train2'\n",
    "]\n",
    "\n",
    "config['TRAIN']['VAL']['val_data_dir'] = [\n",
    "    '/content/TPGSR/data/TextZoom/test/easy',\n",
    "    '/content/TPGSR/data/TextZoom/test/medium',\n",
    "    '/content/TPGSR/data/TextZoom/test/hard'\n",
    "]\n",
    "\n",
    "config['TRAIN']['VAL']['rec_pretrained'] = '/content/TPGSR/pretrained/aster.pth.tar'\n",
    "config['TRAIN']['VAL']['moran_pretrained'] = '/content/TPGSR/pretrained/moran.pth'\n",
    "config['TRAIN']['VAL']['crnn_pretrained'] = '/content/TPGSR/pretrained/crnn.pth'\n",
    "\n",
    "# Adjust for Colab GPU/CPU\n",
    "if torch.cuda.is_available():\n",
    "    config['TRAIN']['cuda'] = True\n",
    "    config['TRAIN']['batch_size'] = 16  # Adjust based on GPU memory\n",
    "else:\n",
    "    config['TRAIN']['cuda'] = False\n",
    "    config['TRAIN']['batch_size'] = 4\n",
    "\n",
    "config['TRAIN']['workers'] = 2\n",
    "config['TRAIN']['epochs'] = 100  # Reduce for demo\n",
    "\n",
    "# Save updated configuration\n",
    "with open('config/super_resolution.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuration updated for Colab environment!\")\n",
    "print(f\"CUDA enabled: {config['TRAIN']['cuda']}\")\n",
    "print(f\"Batch size: {config['TRAIN']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code_fixes"
   },
   "source": [
    "## 4. Code Modifications for Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fix_imports"
   },
   "outputs": [],
   "source": [
    "# Fix ptflops import issues\n",
    "import re\n",
    "\n",
    "# Comment out ptflops imports and usage in interfaces/base.py\n",
    "with open('interfaces/base.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Comment out ptflops related lines\n",
    "content = re.sub(r'^(.*ptflops.*)$', r'# \\1', content, flags=re.MULTILINE)\n",
    "content = re.sub(r'^(.*get_model_complexity_info.*)$', r'# \\1', content, flags=re.MULTILINE)\n",
    "\n",
    "with open('interfaces/base.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "# Do the same for interfaces/super_resolution.py\n",
    "with open('interfaces/super_resolution.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "content = re.sub(r'^(.*ptflops.*)$', r'# \\1', content, flags=re.MULTILINE)\n",
    "content = re.sub(r'^(.*get_model_complexity_info.*)$', r'# \\1', content, flags=re.MULTILINE)\n",
    "\n",
    "with open('interfaces/super_resolution.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"Code modifications completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fix_device_loading"
   },
   "outputs": [],
   "source": [
    "# Fix model loading for CPU/GPU compatibility\n",
    "import re\n",
    "\n",
    "with open('interfaces/base.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Add map_location for torch.load calls\n",
    "device_str = \"torch.device('cuda' if torch.cuda.is_available() else 'cpu')\"\n",
    "content = re.sub(\n",
    "    r'torch\\.load\\(([^)]+)\\)',\n",
    "    f'torch.load(\\\\1, map_location={device_str})',\n",
    "    content\n",
    ")\n",
    "\n",
    "# Fix MORAN initialization for CPU/GPU\n",
    "if torch.cuda.is_available():\n",
    "    content = re.sub(\n",
    "        r\"inputDataType='torch\\.FloatTensor', CUDA=False\",\n",
    "        \"inputDataType='torch.cuda.FloatTensor', CUDA=True\",\n",
    "        content\n",
    "    )\n",
    "else:\n",
    "    content = re.sub(\n",
    "        r\"inputDataType='torch\\.cuda\\.FloatTensor', CUDA=True\",\n",
    "        \"inputDataType='torch.FloatTensor', CUDA=False\",\n",
    "        content\n",
    "    )\n",
    "\n",
    "with open('interfaces/base.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"Device compatibility fixes applied!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "demo"
   },
   "source": [
    "## 5. Demo Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_demo_data"
   },
   "outputs": [],
   "source": [
    "# Create demo directory and test image\n",
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs('demo', exist_ok=True)\n",
    "os.makedirs('demo_results', exist_ok=True)\n",
    "\n",
    "# Create a simple test image with text\n",
    "img = Image.new('RGB', (128, 32), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "try:\n",
    "    # Try to use a system font\n",
    "    font = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 20)\n",
    "except:\n",
    "    # Fallback to default font\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "draw.text((10, 5), \"HELLO\", fill='black', font=font)\n",
    "img.save('demo/test.png')\n",
    "\n",
    "print(\"Demo test image created!\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_demo"
   },
   "outputs": [],
   "source": [
    "# Create and run demo script\n",
    "demo_script = '''\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join('config', 'super_resolution.yaml')\n",
    "config = yaml.load(open(config_path, 'r'), Loader=yaml.Loader)\n",
    "config = EasyDict(config)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create a simple transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load a test image\n",
    "img_path = 'demo/test.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "print(f\"Loaded image from {img_path}\")\n",
    "print(f\"Image tensor shape: {img_tensor.shape}\")\n",
    "\n",
    "# Save the transformed image\n",
    "transformed_img = transforms.ToPILImage()(img_tensor.squeeze(0))\n",
    "transformed_img.save('demo_results/input.png')\n",
    "\n",
    "print(\"Demo preprocessing completed successfully!\")\n",
    "print(\"Input image saved to demo_results/input.png\")\n",
    "'''\n",
    "\n",
    "with open('run_demo.py', 'w') as f:\n",
    "    f.write(demo_script)\n",
    "\n",
    "# Run the demo\n",
    "!python run_demo.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 6. Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start_training"
   },
   "outputs": [],
   "source": [
    "# Start training (this will take a long time)\n",
    "# Uncomment the following line to start training\n",
    "# !python main.py --batch_size=16 --STN --mask --gradient --sr_share --use_distill --without_colorjitter --test_model=TSRN\n",
    "\n",
    "print(\"Training command prepared. Uncomment the line above to start training.\")\n",
    "print(\"Note: Training will take several hours/days depending on your hardware.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## 7. Inference with Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_pretrained_tpgsr"
   },
   "outputs": [],
   "source": [
    "# Download pretrained TPGSR model (if available)\n",
    "# Note: You may need to train your own model or find a pretrained one\n",
    "print(\"To run inference, you need a trained TPGSR model.\")\n",
    "print(\"You can either:\")\n",
    "print(\"1. Train your own model using the training section above\")\n",
    "print(\"2. Download a pretrained model if available\")\n",
    "print(\"3. Use the demo script above for basic functionality testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## 8. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Show input image\n",
    "if os.path.exists('demo_results/input.png'):\n",
    "    img = Image.open('demo_results/input.png')\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.imshow(img)\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Demo completed! Check the demo_results folder for output images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup"
   },
   "source": [
    "## 9. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup_files"
   },
   "outputs": [],
   "source": [
    "# Clean up large files to save space\n",
    "# Uncomment the following lines if you want to clean up\n",
    "\n",
    "# !rm -rf data/TextZoom.zip\n",
    "# !rm -rf data/TextZoom\n",
    "# print(\"Cleanup completed!\")\n",
    "\n",
    "print(\"Cleanup commands prepared. Uncomment to clean up large files.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}